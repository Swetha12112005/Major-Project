{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o4dTk4RmHmQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e955c1-ad38-420c-dc42-32d0d74f5cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset generated and saved as 'placement_data.csv'\n",
            "\n",
            "ðŸš€ Training Models...\n",
            "------------------------------------------------------------\n",
            "Logistic Regression: âœ… Trained | F1: 0.8527\n",
            "Decision Tree: âœ… Trained | F1: 0.7761\n",
            "Random Forest: âœ… Trained | F1: 0.8618\n",
            "\n",
            "ðŸ“Š Model Comparison Report:\n",
            "              Model  Accuracy  Precision   Recall  F1-Score\n",
            "      Random Forest     0.915   0.868852 0.854839  0.861789\n",
            "Logistic Regression     0.905   0.820896 0.887097  0.852713\n",
            "      Decision Tree     0.850   0.722222 0.838710  0.776119\n",
            "\n",
            "ðŸ’¾ Artifacts saved successfully (placement_model.pkl, scaler.pkl, encoder.pkl)\n",
            "\n",
            "ðŸ”® Testing Prediction Function...\n",
            "[{'Input': {'department': 'CSE', 'cgpa': 8.5, 'active_backlogs': 0, 'skill_stack': 'Web Development', 'internships': 2, 'projects': 5, 'aptitude_score': 90, 'communication_score': 9}, 'Prediction': 'Placed', 'Probability': '88.00%'}, {'Input': {'department': 'MECH', 'cgpa': 6.2, 'active_backlogs': 1, 'skill_stack': 'Core', 'internships': 0, 'projects': 2, 'aptitude_score': 65, 'communication_score': 6}, 'Prediction': 'Not Placed', 'Probability': '27.00%'}]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==========================================\n",
        "# 1. DATASET GENERATION\n",
        "# ==========================================\n",
        "def generate_dataset(filename='placement_data.csv', num_samples=1000):\n",
        "    \"\"\"\n",
        "    Generates a synthetic dataset for student placement prediction.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    departments = ['CSE', 'IT', 'ECE', 'MECH', 'CIVIL']\n",
        "    skill_stacks = ['Web Development', 'Data Science', 'Cloud', 'Core']\n",
        "\n",
        "    data = {\n",
        "        'student_id': range(1, num_samples + 1),\n",
        "        'department': np.random.choice(departments, num_samples),\n",
        "        'cgpa': np.random.uniform(5.0, 10.0, num_samples),\n",
        "        'active_backlogs': np.random.randint(0, 5, num_samples),\n",
        "        'skill_stack': np.random.choice(skill_stacks, num_samples),\n",
        "        'internships': np.random.randint(0, 4, num_samples),\n",
        "        'projects': np.random.randint(0, 10, num_samples),\n",
        "        'aptitude_score': np.random.randint(30, 100, num_samples),\n",
        "        'communication_score': np.random.randint(1, 11, num_samples),\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Introduce some missing values to test imputation\n",
        "    df.loc[df.sample(frac=0.05).index, 'cgpa'] = np.nan\n",
        "    df.loc[df.sample(frac=0.05).index, 'communication_score'] = np.nan\n",
        "\n",
        "    # Create a logic for 'placed' target to make the dataset learnable\n",
        "    # (High CGPA + Good Aptitude + No Backlogs = High Chance)\n",
        "    score = (\n",
        "        (df['cgpa'] * 10) +\n",
        "        (df['aptitude_score'] * 0.5) +\n",
        "        (df['communication_score'] * 5) -\n",
        "        (df['active_backlogs'] * 20)\n",
        "    )\n",
        "\n",
        "    # Threshold for placement, adding some randomness\n",
        "    df['placed'] = (score + np.random.normal(0, 10, num_samples) > 110).astype(int)\n",
        "\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"âœ… Dataset generated and saved as '{filename}'\")\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# 2. PREPROCESSING & FEATURE ENGINEERING\n",
        "# ==========================================\n",
        "def preprocess_data(df):\n",
        "    # Drop student_id as it is not a feature\n",
        "    X = df.drop(['student_id', 'placed'], axis=1)\n",
        "    y = df['placed']\n",
        "\n",
        "    # Identify categorical and numerical columns\n",
        "    categorical_cols = ['department', 'skill_stack']\n",
        "    numerical_cols = ['cgpa', 'active_backlogs', 'internships', 'projects', 'aptitude_score', 'communication_score']\n",
        "\n",
        "    # --- Handling Missing Values ---\n",
        "    # Impute Numerical with Mean\n",
        "    num_imputer = SimpleImputer(strategy='mean')\n",
        "    X[numerical_cols] = num_imputer.fit_transform(X[numerical_cols])\n",
        "\n",
        "    # Impute Categorical with Mode\n",
        "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "    X[categorical_cols] = cat_imputer.fit_transform(X[categorical_cols])\n",
        "\n",
        "    # --- Encoding ---\n",
        "    # Use One-Hot Encoding for categorical features\n",
        "    # sparse_output=False returns a numpy array which is easier to concatenate later\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "    X_encoded = encoder.fit_transform(X[categorical_cols])\n",
        "\n",
        "    # Get feature names for encoded columns\n",
        "    encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
        "\n",
        "    # --- Scaling ---\n",
        "    # Apply StandardScaler to numerical features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X[numerical_cols])\n",
        "\n",
        "    # Combine processed numerical and categorical features\n",
        "    X_processed = np.hstack((X_scaled, X_encoded))\n",
        "\n",
        "    # Create a list of all column names for reference (optional)\n",
        "    all_feature_names = list(numerical_cols) + list(encoded_feature_names)\n",
        "\n",
        "    return X_processed, y, encoder, scaler, all_feature_names\n",
        "\n",
        "# ==========================================\n",
        "# 3. MODEL TRAINING & 4. EVALUATION\n",
        "# ==========================================\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    best_model = None\n",
        "    best_score = 0\n",
        "\n",
        "    print(\"\\nðŸš€ Training Models...\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Metrics\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred)\n",
        "        rec = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"Accuracy\": acc,\n",
        "            \"Precision\": prec,\n",
        "            \"Recall\": rec,\n",
        "            \"F1-Score\": f1\n",
        "        })\n",
        "\n",
        "        # Select best model based on F1-Score (balances precision and recall)\n",
        "        if f1 > best_score:\n",
        "            best_score = f1\n",
        "            best_model = model\n",
        "\n",
        "        print(f\"{name}: âœ… Trained | F1: {f1:.4f}\")\n",
        "\n",
        "    # Create Comparison Report\n",
        "    results_df = pd.DataFrame(results).sort_values(by=\"F1-Score\", ascending=False)\n",
        "    print(\"\\nðŸ“Š Model Comparison Report:\")\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# ==========================================\n",
        "# 5. SERIALIZATION\n",
        "# ==========================================\n",
        "def save_artifacts(model, scaler, encoder):\n",
        "    joblib.dump(model, 'placement_model.pkl')\n",
        "    joblib.dump(scaler, 'scaler.pkl')\n",
        "    joblib.dump(encoder, 'encoder.pkl')\n",
        "    print(\"\\nðŸ’¾ Artifacts saved successfully (placement_model.pkl, scaler.pkl, encoder.pkl)\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. PREDICTION FUNCTION\n",
        "# ==========================================\n",
        "def predict_placement(student_data):\n",
        "    \"\"\"\n",
        "    Predicts placement status for a new student.\n",
        "    student_data: Dictionary or List of Dictionaries\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load saved artifacts\n",
        "        model = joblib.load('placement_model.pkl')\n",
        "        scaler = joblib.load('scaler.pkl')\n",
        "        encoder = joblib.load('encoder.pkl')\n",
        "\n",
        "        # Convert input to DataFrame\n",
        "        input_df = pd.DataFrame(student_data)\n",
        "\n",
        "        # Reconstruct column lists (must match training)\n",
        "        numerical_cols = ['cgpa', 'active_backlogs', 'internships', 'projects', 'aptitude_score', 'communication_score']\n",
        "        categorical_cols = ['department', 'skill_stack']\n",
        "\n",
        "        # 1. Handle Missing Values (using SimpleImputer logic manually or pre-fit imputers)\n",
        "        # For simplicity here, we fill with 0 if missing, or we could load saved imputers.\n",
        "        # Assuming saved imputers for robust production code:\n",
        "        # Here we assume input is complete for brevity, but fill NaN just in case.\n",
        "        input_df[numerical_cols] = input_df[numerical_cols].fillna(0)\n",
        "        input_df[categorical_cols] = input_df[categorical_cols].fillna('Unknown')\n",
        "\n",
        "        # 2. Scale Numerical\n",
        "        input_scaled = scaler.transform(input_df[numerical_cols])\n",
        "\n",
        "        # 3. Encode Categorical\n",
        "        input_encoded = encoder.transform(input_df[categorical_cols])\n",
        "\n",
        "        # 4. Combine\n",
        "        input_processed = np.hstack((input_scaled, input_encoded))\n",
        "\n",
        "        # 5. Predict\n",
        "        prediction_class = model.predict(input_processed)\n",
        "        prediction_prob = model.predict_proba(input_processed)[:, 1] # Probability of Class 1\n",
        "\n",
        "        results = []\n",
        "        for i in range(len(student_data)):\n",
        "            results.append({\n",
        "                \"Input\": student_data[i],\n",
        "                \"Prediction\": \"Placed\" if prediction_class[i] == 1 else \"Not Placed\",\n",
        "                \"Probability\": f\"{prediction_prob[i] * 100:.2f}%\"\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error during prediction: {str(e)}\"\n",
        "\n",
        "# ==========================================\n",
        "# MAIN EXECUTION\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 1: Generate Data\n",
        "    df = generate_dataset()\n",
        "\n",
        "    # Step 2: Preprocess\n",
        "    X, y, encoder, scaler, feature_names = preprocess_data(df)\n",
        "\n",
        "    # Split Data (80% Train, 20% Test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Step 3 & 4: Train and Evaluate\n",
        "    best_model = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Step 5: Save Model\n",
        "    save_artifacts(best_model, scaler, encoder)\n",
        "\n",
        "    # Step 6: Test Prediction Function with a new student\n",
        "    print(\"\\nðŸ”® Testing Prediction Function...\")\n",
        "\n",
        "    new_student = [{\n",
        "        'department': 'CSE',\n",
        "        'cgpa': 8.5,\n",
        "        'active_backlogs': 0,\n",
        "        'skill_stack': 'Web Development', # Added closing quote\n",
        "        'internships': 2,\n",
        "        'projects': 5,\n",
        "        'aptitude_score': 90,\n",
        "        'communication_score': 9\n",
        "    },{\n",
        "        'department': 'MECH',\n",
        "        'cgpa': 6.2,\n",
        "        'active_backlogs': 1,\n",
        "        'skill_stack': 'Core',\n",
        "        'internships': 0,\n",
        "        'projects': 2,\n",
        "        'aptitude_score': 65,\n",
        "        'communication_score': 6\n",
        "    }]\n",
        "\n",
        "    predictions = predict_placement(new_student)\n",
        "    print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-frfdDSH0Xo"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}